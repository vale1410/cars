First, we would like to thank the reviewers for their comments.

Review1
* The cardinality of I in w_S^k" is the number of variables in I assigned to 1
* The explanation is not optimal. We have examples but we did not include them
for lack of space
* item Minisat of Section 6: We generate one atmostseqcard for each class and
for each option. For each class the atmostseq follows from its
options by taking the capacity constraint with minimal value for (u/q), i.e.
the strictest. 
* we used restarts for all approaches 
* we update the usage rates dynamically. 

 Review2
* Different encodings of cardinality constraints: 
* Regarding SCA (AtMost for each subsequence) the largest restriction is 2/5
and too short to take advantage of other cardinality encodings. In fact we
tried encodings that do not use auxiliary variables for these constraints
(posting all prime implicates is possible for small values) and did not
experience great difference. Regarding the SCS (and thus much larger values)
we do indirectly compare to alternative encodings of cardinality as minisat+
translates through sorting networks (or BDDs). We see advantage in the SCS
encoding as we can reuse the auxiliary variables, something that would not
work for the sorting networks.  Future work is to experiment further with SAT
encodings.  
*The experiments were all done on the same machine.

Review3
* CP + nogoods generated by the new explanations were in fact tested (denoted
"hybrid"). The current version of Mistral actually handles clause learning on
SAT and pseudo-Boolean instances (i.e., it implements all standards features
of CDCL).
* The reviewer points out in detail the similarities and differences to [2].
However, at the end of the day, our approach is different. We introduce our
encoding by an extension of a sequential counter and we miss to show the
proximity to the encoding of regular/gen-sequenc.  Whilst we accept this
criticism and will revise the paper, we believe that the SAT encodings add
novelty and are worth reporting:
* There are three differences to the encoding in [2] (as mentioned by the
reviewer): 
1) Using the >=d semantics for the auxiliary variables, branching becomes more
fine-grained and less "committing" than for =d semantics. 
2) On the auxiliary variables we gain propagation due to more binary clauses.
1) and 2) are related to the comparison of "direct encoding" vs. "order
encoding".
3) In E3 we encode both the SCS encoding together with SCA for each capacity
constraint (this variant is not done in [2]) and we sketch that this achieves
GAC by reusing a Lemma for the CP propagator. The proof is rather technical,
but will be included in the revised paper.
